# bRPC 源码分析「二、内存管理」

### 1. Object Pool

代码中频繁使用的结构体大部分是等长的。根据该原理，bRPC 中设计了一个对象池，简化定长对象的分配和回收策略，尽可能地在 Thread Local 环境中进行内存操作。申请对象时按照如下的规则 BAIDU_OBJECT_POOL_GET：

1. 本线程回收列表中是否有对象，有则直接返回
2. 尝试从全局获取一个回收列表，有则直接返回回收列表中的一个对象
3. 本线程内存块中是否还有足够的内存，有则构造一个对象返回
4. 本线程申请一个新的内存块，构造对象返回

```c++
// object_pool.h
// Get an object typed |T|. The object should be cleared before usage.
// NOTE: T must be default-constructible.
template <typename T> inline T *get_object() {
  return ObjectPool<T>::singleton()->get_object();
}

// object_pool_inl.h
inline T *ObjectPool<T>::get_object() {
  LocalPool *lp = get_or_new_local_pool();  // 获取 TLS 单例
  if (BAIDU_LIKELY(lp != NULL)) {
    return lp->get();  // 分配对象
  }
  return NULL;
}

template <typename T>
BAIDU_THREAD_LOCAL
    typename ObjectPool<T>::LocalPool *ObjectPool<T>::_local_pool = NULL

inline LocalPool *ObjectPool<T>::get_or_new_local_pool() {
  LocalPool *lp = _local_pool;
  if (BAIDU_LIKELY(lp != NULL)) {
    return lp;
  }
  lp = new (std::nothrow) LocalPool(this);
  if (NULL == lp) {
    return NULL;
  }
  // 如果用 C++11 的 thread_local，可以省略掉这里的加锁和析构注册
  BAIDU_SCOPED_LOCK(_change_thread_mutex); // avoid race with clear()
  _local_pool = lp;
  butil::thread_atexit(LocalPool::delete_local_pool, lp);
  _nlocal.fetch_add(1, butil::memory_order_relaxed);
  return lp;
}

class BAIDU_CACHELINE_ALIGNMENT LocalPool {
 public:
  explicit LocalPool(ObjectPool *pool)
      : _pool(pool), _cur_block(NULL), _cur_block_index(0) {
    _cur_free.nfree = 0;
  }

  ~LocalPool() {
    // Add to global _free if there're some free objects
    if (_cur_free.nfree) {
      _pool->push_free_chunk(_cur_free);
    }

    _pool->clear_from_destructor_of_local_pool();
  }

  static void delete_local_pool(void *arg) { delete (LocalPool *)arg; }

// We need following macro to construct T with different CTOR_ARGS
// which may include parenthesis because when T is POD, "new T()"
// and "new T" are different: former one sets all fields to 0 which
// we don't want.
#define BAIDU_OBJECT_POOL_GET(CTOR_ARGS)                                       \
  /* Fetch local free ptr */                                                   \
  if (_cur_free.nfree) {                                                       \
    BAIDU_OBJECT_POOL_FREE_ITEM_NUM_SUB1;                                      \
    return _cur_free.ptrs[--_cur_free.nfree];                                  \
  }                                                                            \
  /* Fetch a FreeChunk from global.                                            \
     TODO: Popping from _free needs to copy a FreeChunk which is               \
     costly, but hardly impacts amortized performance. */                      \
  if (_pool->pop_free_chunk(_cur_free)) {                                      \
    BAIDU_OBJECT_POOL_FREE_ITEM_NUM_SUB1;                                      \
    return _cur_free.ptrs[--_cur_free.nfree];                                  \
  }                                                                            \
  /* Fetch memory from local block */                                          \
  if (_cur_block && _cur_block->nitem < BLOCK_NITEM) {                         \
    T *obj = new ((T *)_cur_block->items + _cur_block->nitem) T CTOR_ARGS;     \
    if (!ObjectPoolValidator<T>::validate(obj)) {                              \
      obj->~T();                                                               \
      return NULL;                                                             \
    }                                                                          \
    ++_cur_block->nitem;                                                       \
    return obj;                                                                \
  }                                                                            \
  /* Fetch a Block from global */                                              \
  _cur_block = add_block(&_cur_block_index);                                   \
  if (_cur_block != NULL) {                                                    \
    T *obj = new ((T *)_cur_block->items + _cur_block->nitem) T CTOR_ARGS;     \
    if (!ObjectPoolValidator<T>::validate(obj)) {                              \
      obj->~T();                                                               \
      return NULL;                                                             \
    }                                                                          \
    ++_cur_block->nitem;                                                       \
    return obj;                                                                \
  }                                                                            \
  return NULL;

  inline T *get() { BAIDU_OBJECT_POOL_GET(); }

  template <typename A1> inline T *get(const A1 &a1) {
    BAIDU_OBJECT_POOL_GET((a1));
  }

  template <typename A1, typename A2>
  inline T *get(const A1 &a1, const A2 &a2) {
    BAIDU_OBJECT_POOL_GET((a1, a2));
  }

#undef BAIDU_OBJECT_POOL_GET

  inline int return_object(T *ptr) {
    // Return to local free list
    // 线程内对象数量没有超过阈值，仍缓存在线程中
    if (_cur_free.nfree < ObjectPool::free_chunk_nitem()) {
      _cur_free.ptrs[_cur_free.nfree++] = ptr;
      BAIDU_OBJECT_POOL_FREE_ITEM_NUM_ADD1;
      return 0;
    }
    // Local free list is full, return it to global.
    // For copying issue, check comment in upper get()
    // 超过阈值，将线程中对象归还到全局缓存中
    if (_pool->push_free_chunk(_cur_free)) {
      _cur_free.nfree = 1;
      _cur_free.ptrs[0] = ptr;
      BAIDU_OBJECT_POOL_FREE_ITEM_NUM_ADD1;
      return 0;
    }
    return -1;
  }

 private:
  ObjectPool *_pool;
  Block *_cur_block;
  size_t _cur_block_index;
  FreeChunk _cur_free;
};

// 从全局缓存中获取一批对象
bool ObjectPool<T>::pop_free_chunk(FreeChunk &c) {
  // Critical for the case that most return_object are called in
  // different threads of get_object.
  if (_free_chunks.empty()) {
    return false;
  }
  pthread_mutex_lock(&_free_chunks_mutex);
  if (_free_chunks.empty()) {
    pthread_mutex_unlock(&_free_chunks_mutex);
    return false;
  }
  // 从 _free_chunks 尾部 pop 一批对象
  DynamicFreeChunk *p = _free_chunks.back();
  _free_chunks.pop_back();
  pthread_mutex_unlock(&_free_chunks_mutex);
  c.nfree = p->nfree;
  memcpy(c.ptrs, p->ptrs, sizeof(*p->ptrs) * p->nfree);
  free(p);
  return true;
}

// When a thread needs memory, it allocates a Block. To improve locality,
// items in the Block are only used by the thread.
// To support cache-aligned objects, align Block.items by cacheline.
struct BAIDU_CACHELINE_ALIGNMENT Block {
  char items[sizeof(T) * BLOCK_NITEM];
  size_t nitem;

  Block() : nitem(0) {}
};

// An Object addresses at most OP_MAX_BLOCK_NGROUP BlockGroups,
// each BlockGroup addresses at most OP_GROUP_NBLOCK blocks. So an
// object addresses at most OP_MAX_BLOCK_NGROUP * OP_GROUP_NBLOCK Blocks.
// 用来存储一批 blocks 的地址
struct BlockGroup {
  butil::atomic<size_t> nblock;
  butil::atomic<Block *> blocks[OP_GROUP_NBLOCK];

  BlockGroup() : nblock(0) {
    // We fetch_add nblock in add_block() before setting the entry,
    // thus address_resource() may sees the unset entry. Initialize
    // all entries to NULL makes such address_resource() return NULL.
    memset(blocks, 0, sizeof(butil::atomic<Block *>) * OP_GROUP_NBLOCK);
  }
};

// Create a Block and append it to right-most BlockGroup.
static Block *ObjectPool<T>::add_block(size_t *index) {
  Block *const new_block = new (std::nothrow) Block;
  if (NULL == new_block) {
    return NULL;
  }
  size_t ngroup;
  do {
    ngroup = _ngroup.load(butil::memory_order_acquire);
    if (ngroup >= 1) {
      BlockGroup *const g =
        _block_groups[ngroup - 1].load(butil::memory_order_consume);
      const size_t block_index =
        g->nblock.fetch_add(1, butil::memory_order_relaxed);  // 原子加
      if (block_index < OP_GROUP_NBLOCK) {
        // 如果当前 group 的大小没有超过阈值，成功增加 block
        g->blocks[block_index].store(new_block, butil::memory_order_release);
        *index = (ngroup - 1) * OP_GROUP_NBLOCK + block_index;
        return new_block;
      }
      // 否则将增加的计数减去，增加新的 group
      g->nblock.fetch_sub(1, butil::memory_order_relaxed);
    }
  } while (add_block_group(ngroup));

  // Fail to add_block_group.
  delete new_block;
  return NULL;
}

// Create a BlockGroup and append it to _block_groups.
// Shall be called infrequently because a BlockGroup is pretty big.
static bool add_block_group(size_t old_ngroup) {
  BlockGroup *bg = NULL;
  BAIDU_SCOPED_LOCK(_block_group_mutex);  // 加锁
  const size_t ngroup = _ngroup.load(butil::memory_order_acquire);
  if (ngroup != old_ngroup) {
    // Other thread got lock and added group before this thread.
    // 有其他线程成功增加了 block group，需要重试
    return true;
  }
  if (ngroup < OP_MAX_BLOCK_NGROUP) {
    bg = new (std::nothrow) BlockGroup;
    if (NULL != bg) {
      // Release fence is paired with consume fence in add_block()
      // to avoid un-constructed bg to be seen by other threads.
      // 成功增加 block group
      _block_groups[ngroup].store(bg, butil::memory_order_release);
      _ngroup.store(ngroup + 1, butil::memory_order_release);
    }
  }
  return bg != NULL;
}
```

回收对象时不进行析构和删除，仅将其指针加入本线程的缓存列表中，积累后一定阈值后有锁地加入全局缓存中。注意申请对象时是申请整段内存，返回的对象并不具有其对应内存的所有权，必须调用内存池提供的 `return_object` 接口进行回收。默认实现中所有申请的对象都不会进行**析构**和**删除**，意味着内存占用是不会回落的，类似 `std::vector`。

### 2. Resource Pool

资源池的设计与上文中的对象池类似，不同的是引入了 `ResourceId` 的概念，表示该资源在对象池中的偏移量：

```c++
// resource_pool_inl.h
template <typename T> struct ResourceId {
  uint64_t value;

  operator uint64_t() const { return value; }

  template <typename T2> ResourceId<T2> cast() const {
    ResourceId<T2> id = {value};
    return id;
  }
};

template <typename T, size_t NITEM> struct ResourcePoolFreeChunk {
  size_t nfree;
  ResourceId<T> ids[NITEM];
};

    // We need following macro to construct T with different CTOR_ARGS
    // which may include parenthesis because when T is POD, "new T()"
    // and "new T" are different: former one sets all fields to 0 which
    // we don't want.
#define BAIDU_RESOURCE_POOL_GET(CTOR_ARGS)                                     \
  /* Fetch local free id */                                                    \
  if (_cur_free.nfree) {                                                       \
    const ResourceId<T> free_id = _cur_free.ids[--_cur_free.nfree];            \
    *id = free_id;                                                             \
    BAIDU_RESOURCE_POOL_FREE_ITEM_NUM_SUB1;                                    \
    return unsafe_address_resource(free_id);                                   \
  }                                                                            \
  /* Fetch a FreeChunk from global.                                            \
     TODO: Popping from _free needs to copy a FreeChunk which is               \
     costly, but hardly impacts amortized performance. */                      \
  if (_pool->pop_free_chunk(_cur_free)) {                                      \
    --_cur_free.nfree;                                                         \
    const ResourceId<T> free_id = _cur_free.ids[_cur_free.nfree];              \
    *id = free_id;                                                             \
    BAIDU_RESOURCE_POOL_FREE_ITEM_NUM_SUB1;                                    \
    return unsafe_address_resource(free_id);                                   \
  }                                                                            \
  /* Fetch memory from local block */                                          \
  if (_cur_block && _cur_block->nitem < BLOCK_NITEM) {                         \
    id->value = _cur_block_index * BLOCK_NITEM + _cur_block->nitem;            \
    T *p = new ((T *)_cur_block->items + _cur_block->nitem) T CTOR_ARGS;       \
    if (!ResourcePoolValidator<T>::validate(p)) {                              \
      p->~T();                                                                 \
      return NULL;                                                             \
    }                                                                          \
    ++_cur_block->nitem;                                                       \
    return p;                                                                  \
  }                                                                            \
  /* Fetch a Block from global */                                              \
  _cur_block = add_block(&_cur_block_index);                                   \
  if (_cur_block != NULL) {                                                    \
    id->value = _cur_block_index * BLOCK_NITEM + _cur_block->nitem;            \
    T *p = new ((T *)_cur_block->items + _cur_block->nitem) T CTOR_ARGS;       \
    if (!ResourcePoolValidator<T>::validate(p)) {                              \
      p->~T();                                                                 \
      return NULL;                                                             \
    }                                                                          \
    ++_cur_block->nitem;                                                       \
    return p;                                                                  \
  }                                                                            \
```

注意 `ResourceId` 的计算公式：`_cur_block_index * BLOCK_NITEM + _cur_block->nitem`，可以在 $\mathcal O(1)$ 的时间内反推对象的内存地址：

```c++
static inline T *address_resource(ResourceId<T> id) {
  const size_t block_index = id.value / BLOCK_NITEM;
  const size_t group_index = (block_index >> RP_GROUP_NBLOCK_NBIT);
  if (__builtin_expect(group_index < RP_MAX_BLOCK_NGROUP, 1)) {
    BlockGroup *bg =
      _block_groups[group_index].load(butil::memory_order_consume);
    if (__builtin_expect(bg != NULL, 1)) {
      Block *b = bg->blocks[block_index & (RP_GROUP_NBLOCK - 1)].load(
        butil::memory_order_consume);
      if (__builtin_expect(b != NULL, 1)) {
        const size_t offset = id.value - block_index * BLOCK_NITEM;
        if (__builtin_expect(offset < b->nitem, 1)) {
          return (T *)b->items + offset;
        }
      }
    }
  }

  return NULL;
}
```

大多数场景下 `ResourceId` 小于 $2^{32}$（除非全局对象数量超过 40+ 亿），bRPC 利用这一点将其编码为 64 位 ID 的一部分，余下的部分放置对象的版本。以下描述引用自参考文献一。

> 对象可以被归还，但归还后对象并没有删除，也没有被析构，而是仅仅进入回收列表。下次申请时可能会取到这种使用过的对象，需要重置后才能使用。当对象被归还后，通过对应的偏移量仍可以访问到对象，即 ResourcePool 只负责内存分配，并不解决 ABA 问题。
>
> bthread 的大部分函数都需要在 O(1) 时间内通过 bthread_t 访问到 TaskMeta，并且当 bthread_t 失效后，访问应返回 NULL 以让函数做出返回错误。解决方法是：bthread_t 由 32 位的版本和 32 位的偏移量组成。版本解决 [ABA 问题](http://en.wikipedia.org/wiki/ABA_problem)，偏移量由ResourcePool 分配。查找时先通过偏移量获得 TaskMeta，再检查版本，如果版本不匹配，说明 bthread 失效了。

```c++
// task_group_inl.h
// Utilities to manipulate bthread_t
inline bthread_t make_tid(uint32_t version, butil::ResourceId<TaskMeta> slot) {
  return (((bthread_t)version) << 32) | (bthread_t)slot.value;
}

inline butil::ResourceId<TaskMeta> get_slot(bthread_t tid) {
  butil::ResourceId<TaskMeta> id = {(tid & 0xFFFFFFFFul)};
  return id;
}
inline uint32_t get_version(bthread_t tid) {
  return (uint32_t)((tid >> 32) & 0xFFFFFFFFul);
}

inline TaskMeta *TaskGroup::address_meta(bthread_t tid) {
  // TaskMeta * m = address_resource<TaskMeta>(get_slot(tid));
  // if (m != NULL && m->version == get_version(tid)) {
  //     return m;
  // }
  // return NULL;
  return address_resource(get_slot(tid));
}

// task_group.cpp
// 版本使用举例
bool TaskGroup::exists(bthread_t tid) {
  if (tid != 0) { // tid of bthread is never 0.
    TaskMeta *m = address_meta(tid);
    if (m != NULL) {
      return (*m->version_butex == get_version(tid));  // 判断版本是否一致
    }
  }
  return false;
}
```

### References

1. ["bRPC Memory Management", *incubator-brpc*](https://github.com/apache/incubator-brpc/blob/master/docs/cn/memory_management.md)

