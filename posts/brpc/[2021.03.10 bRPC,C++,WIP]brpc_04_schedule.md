# bRPC 源码分析「四、协程调度」

### 1. Task Runner

bRPC 中所有协程的入口都是 `TaskGroup::task_runner` 函数，该函数的具体实现为：

```c++
void TaskGroup::task_runner(intptr_t skip_remained) {
  // NOTE: tls_task_group is volatile since tasks are moved around
  //       different groups.
  TaskGroup *g = tls_task_group;

  if (!skip_remained) {
    // 用户函数执行前，先执行 remained 函数
    while (g->_last_context_remained) {
      RemainedFn fn = g->_last_context_remained;
      g->_last_context_remained = NULL;
      fn(g->_last_context_remained_arg);
      g = tls_task_group;
    }
  }

  do {
    // Meta and identifier of the task is persistent in this run.
    // 通过 TLS 获取当前线程待执行的任务 TaskMeta
    TaskMeta *const m = g->_cur_meta;

    // Not catch exceptions except ExitException which is for implementing
    // bthread_exit(). User code is intended to crash when an exception is
    // not caught explicitly. This is consistent with other threading
    // libraries.
    // 通过捕获 ExitException 异常，实现协程中执行 bthread_exit() 时提前退出
    void *thread_return;
    try {
      // 执行用户指定的函数，中途可能触发协程切换
      thread_return = m->fn(m->arg);
    } catch (ExitException &e) {
      thread_return = e.value();
    }

    // Group is probably changed
    // 用户指定的函数中可能触发协程切换，需要通过 TLS 重新确定当前的线程
    g = tls_task_group;

    // TODO: Save thread_return
    (void)thread_return;

    // Logging must be done before returning the keytable, since the logging lib
    // use bthread local storage internally, or will cause memory leak.
    // FIXME: the time from quiting fn to here is not counted into cputime
    if (m->attr.flags & BTHREAD_LOG_START_AND_FINISH) {
      LOG(INFO) << "Finished bthread " << m->tid
                << ", cputime=" << m->stat.cputime_ns / 1000000.0 << "ms";
    }

    // Clean tls variables, must be done before changing version_butex
    // otherwise another thread just joined this thread may not see side
    // effects of destructing tls variables.
    KeyTable *kt = tls_bls.keytable;
    if (kt != NULL) {
      return_keytable(m->attr.keytable_pool, kt);
      // After deletion: tls may be set during deletion.
      tls_bls.keytable = NULL;
      m->local_storage.keytable = NULL; // optional
    }

    // Increase the version and wake up all joiners, if resulting version
    // is 0, change it to 1 to make bthread_t never be 0. Any access
    // or join to the bthread after changing version will be rejected.
    // The spinlock is for visibility of TaskGroup::get_attr.
    {
      BAIDU_SCOPED_LOCK(m->version_lock);
      // 通过增加版本的方式标记当前 TaskMeta 不再可用
      if (0 == ++*m->version_butex) {
        ++*m->version_butex;
      }
    }
    butex_wake_except(m->version_butex, 0);

    g->_control->_nbthreads << -1;
    // 
    g->set_remained(TaskGroup::_release_last_context, m);
    ending_sched(&g);

    // 调度后可能拿到一个 pthread 任务，则继续在该函数中执行
  } while (g->_cur_meta->tid != g->_main_tid);

  // Was called from a pthread and we don't have BTHREAD_STACKTYPE_PTHREAD
  // tasks to run, quit for more tasks.
}

void TaskGroup::_release_last_context(void* arg) {
  // 下一个协程用户函数启动前，执行该函数
  TaskMeta* m = static_cast<TaskMeta*>(arg);
  if (m->stack_type() != stack_type_t::PTHREAD) {
    // 回收协程栈
    return_stack(m->release_stack());
  } else {
    m->set_stack(nullptr);
  }
  // 回收 TaskMeta
  mem::return_resource(get_slot(m->tid));
}

// 当前协程函数执行结束时，尝试拿取新任务执行
void TaskGroup::ending_sched(TaskGroup** pg) {
  TaskGroup* g = *pg;
  task_t next_tid = 0;
  const bool popped = g->_rq.pop(&next_tid);
  if (!popped && !g->steal_task(&next_tid)) {
    // Jump to main task if there's no task to run.
    // 如果没有新任务，则跳回主协程
    next_tid = g->_main_tid;
  }

  TaskMeta* const cur_meta = g->_cur_meta;
  TaskMeta* next_meta = address_meta(next_tid);
  if (next_meta->stack == nullptr) {
    if (next_meta->stack_type() == cur_meta->stack_type()) {
      // also works with pthread_task scheduling to pthread_task, the
      // transfered stack is just _main_stack.
      // 将当前协程使用的栈转移给新任务，减少一次栈分配
      next_meta->set_stack(cur_meta->release_stack());
    } else {
      auto stk = get_stack(next_meta->stack_type(), task_runner);
      if (stk) {
        next_meta->set_stack(stk);
      } else {
        // stack_type is BTHREAD_STACKTYPE_PTHREAD or out of memory,
        // In latter case, attr is forced to be BTHREAD_STACKTYPE_PTHREAD.
        // This basically means that if we can't allocate stack, run
        // the task in pthread directly.
        // 对于 pthread 任务或者栈空间不足的情况，直接在主协程中执行这些任务
        next_meta->attr.stack_type = stack_type_t::PTHREAD;
        next_meta->set_stack(g->_main_stack);
      }
    }
  }
  sched_to(pg, next_meta);  // 调度
}

void TaskGroup::sched_to(TaskGroup** pg, TaskMeta* next_meta) {
  TaskGroup* g = *pg;
  // Save errno so that errno is task-specific.
  const int saved_errno = errno;
  // void* saved_unique_user_ptr = tls_unique_user_ptr;

  TaskMeta* const cur_meta = g->_cur_meta;
  const int64_t now = utils::cpuwide_time_ns();
  const int64_t elp_ns = now - g->_last_run_ns;
  g->_last_run_ns = now;
  cur_meta->stat.cputime_ns += elp_ns;
  if (cur_meta->tid != g->main_tid()) {
    g->_cumulated_cputime_ns += elp_ns;
  }
  ++cur_meta->stat.nswitch;
  ++g->_nswitch;
  // Switch to the task
  if (PAXOS_LIKELY(next_meta != cur_meta)) {
    g->_cur_meta = next_meta;
    // Switch tls_bls
    cur_meta->local_storage = tls_bls;
    tls_bls = next_meta->local_storage;

    // Logging must be done after switching the local storage, since the logging
    // lib use task local storage internally, or will cause memory leak.
    if ((cur_meta->attr.flags & LOG_CONTEXT_SWITCH) ||
        (next_meta->attr.flags & LOG_CONTEXT_SWITCH)) {
      LOG(INFO) << "Switch task: " << cur_meta->tid << " -> " << next_meta->tid;
    }

    if (cur_meta->stack != nullptr) {
      if (next_meta->stack != cur_meta->stack) {
        // 当栈不相同时才执行协程切换
        // 对于 pthread 任务：
        // 1. pthread -> pthread 不切换
        // 2. pthread -> bthread 从 main_stack 切换到协程栈
        // 3. bthread -> pthread 从协程栈协换到 main_stack
        jump_stack(cur_meta->stack, next_meta->stack);
        // probably went to another group, need to assign g again.
        g = tls_task_group;
      }
    }
    // else because of ending_sched(including pthread_task->pthread_task)
  } else {
    LOG(FATAL) << "task=" << g->current_tid() << " sched_to itself!";
  }

  // 当协程切回时，也需要执行指定的 Remained 函数
  while (g->_last_context_remained) {
    RemainedFn fn = g->_last_context_remained;
    g->_last_context_remained = nullptr;
    fn(g->_last_context_remained_arg);
    g = tls_task_group;
  }

  // Restore errno
  errno = saved_errno;
  // tls_unique_user_ptr = saved_unique_user_ptr;

  *pg = g;
}

void TaskGroup::run_main_task() {
  TaskGroup* dummy = this;
  task_t tid;
  while (wait_task(&tid)) {
    TaskGroup::sched_to(&dummy, tid);
    // DCHECK_EQ(this, dummy);
    // DCHECK_EQ(_cur_meta->stack, _main_stack);
    if (_cur_meta->tid != _main_tid) {
      // 对于没有切换到协程栈的任务，在主线程中执行
      TaskGroup::task_runner(1);
    }
  }
  // stop_main_task() was called.
  // Don't forget to add elapse of last wait_task.
  current_task()->stat.cputime_ns += utils::cpuwide_time_ns() - _last_run_ns;
}
```

### 2. Timer Thread

> WIP

### References

1. ["bRPC Timer Keeping", *incubator-brpc*](https://github.com/apache/incubator-brpc/blob/master/docs/cn/timer_keeping.md)

