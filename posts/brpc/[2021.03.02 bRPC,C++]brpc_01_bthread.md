# bRPC 源码分析「一、bthread」

### 1. Context Switching

bthread 中使用 [libcontext](https://github.com/twlostow/libcontext) 实现协程间的切换，原理类似[汇编魔法实现 C++ 协程](/programming/cpp_magic_coroutine.html)中的方法。看一个单元测试中的例子（[在线执行](https://godbolt.org/z/sf7vhK)）：

```c++
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

#include <iostream>

typedef void *bthread_fcontext_t;

extern "C" bthread_fcontext_t bthread_make_fcontext(void *sp, size_t size,
                                                    void (*fn)(intptr_t));
__asm(
    ".text\n"
    ".globl bthread_make_fcontext\n"
    ".type bthread_make_fcontext,@function\n"
    ".align 16\n"
    "bthread_make_fcontext:\n"
    "    movq  %rdi, %rax\n"
    "    andq  $-16, %rax\n"
    "    leaq  -0x48(%rax), %rax\n"
    "    movq  %rdx, 0x38(%rax)\n"
    "    stmxcsr  (%rax)\n"
    "    fnstcw   0x4(%rax)\n"
    "    leaq  finish(%rip), %rcx\n"
    "    movq  %rcx, 0x40(%rax)\n"
    "    ret \n"
    "finish:\n"
    "    xorq  %rdi, %rdi\n"
    "    call  _exit@PLT\n"
    "    hlt\n"
    ".size bthread_make_fcontext,.-bthread_make_fcontext\n"
    ".section .note.GNU-stack,\"\",%progbits\n"
    ".previous\n");

extern "C" intptr_t bthread_jump_fcontext(bthread_fcontext_t *ofc,
                                          bthread_fcontext_t nfc, intptr_t vp);
__asm(
    ".text\n"
    ".globl bthread_jump_fcontext\n"
    ".type bthread_jump_fcontext,@function\n"
    ".align 16\n"
    "bthread_jump_fcontext:\n"
    "    pushq  %rbp  \n"
    "    pushq  %rbx  \n"
    "    pushq  %r15  \n"
    "    pushq  %r14  \n"
    "    pushq  %r13  \n"
    "    pushq  %r12  \n"
    "    leaq  -0x8(%rsp), %rsp\n"
    "    movq  %rsp, (%rdi)\n"
    "    movq  %rsi, %rsp\n"
    "    leaq  0x8(%rsp), %rsp\n"
    "    popq  %r12  \n"
    "    popq  %r13  \n"
    "    popq  %r14  \n"
    "    popq  %r15  \n"
    "    popq  %rbx  \n"
    "    popq  %rbp  \n"
    "    popq  %r8\n"
    "    movq  %rdx, %rax\n"
    "    movq  %rdx, %rdi\n"
    "    jmp  *%r8\n"
    ".size bthread_jump_fcontext,.-bthread_jump_fcontext\n"
    ".section .note.GNU-stack,\"\",%progbits\n"
    ".previous\n");

bthread_fcontext_t fcm;
bthread_fcontext_t fc;

typedef std::pair<int, int> pair_t;
static void f(intptr_t param) {
  pair_t *p = (pair_t *)param;
  printf("In Routine: fcm %p fc %p\n", fcm, fc);

  p = (pair_t *)bthread_jump_fcontext(&fc, fcm,
                                      (intptr_t)(p->first + p->second));

  printf("In Routine Again: fcm %p fc %p\n", fcm, fc);
  bthread_jump_fcontext(&fc, fcm, (intptr_t)(p->first + p->second));
}

int main() {
  fcm = NULL;
  std::size_t size(8192);
  void *sp = malloc(size);

  pair_t p(std::make_pair(2, 7));
  fc = bthread_make_fcontext((char *)sp + size, size, f);

  printf("Start Routine: fcm %p fc %p\n", fcm, fc);
  int res = (int)bthread_jump_fcontext(&fcm, fc, (intptr_t)&p);
  printf("Back to Main: %d + %d = %d\n", p.first, p.second, res);

  p = std::make_pair(5, 6);
  printf("Resume Routine: fcm %p fc %p\n", fcm, fc);
  res = (int)bthread_jump_fcontext(&fcm, fc, (intptr_t)&p);
  printf("Back to Main Again: %d + %d = %d\n", p.first, p.second, res);

  return 0;
}
```

### 2. Work Stealing

核心思路是当本线程内没有待执行的任务时，从其他线程的任务队列中窃取任务执行。首先来看 work stealing 时使用的无锁队列 [src/bthread/work_stealing_queue.h](https://github.com/apache/incubator-brpc/blob/0.9.7/src/bthread/work_stealing_queue.h)：

```c++
template <typename T>
class WorkStealingQueue {
 public:
  WorkStealingQueue() : _bottom(1), _capacity(0), _buffer(NULL), _top(1) {}

  int init(size_t capacity) {
    if (_capacity != 0) {
      LOG(ERROR) << "Already initialized";
      return -1;
    }
    if (capacity == 0) {
      LOG(ERROR) << "Invalid capacity=" << capacity;
      return -1;
    }
    if (capacity & (capacity - 1)) {
      LOG(ERROR) << "Invalid capacity=" << capacity
                 << " which must be power of 2";
      return -1;
    }
    _buffer = new (std::nothrow) T[capacity];
    if (NULL == _buffer) {
      return -1;
    }
    _capacity = capacity;
    return 0;
  }

  // 从底部追加，非线程安全，与 steal 线程安全
  bool push(const T& x) {
    const size_t b = _bottom.load(butil::memory_order_relaxed);
    const size_t t = _top.load(butil::memory_order_acquire);
    if (b >= t + _capacity) {  // Full queue.
      return false;
    }
    _buffer[b & (_capacity - 1)] = x;
    _bottom.store(b + 1, butil::memory_order_release);
    return true;
  }

  // 从底部弹出，非线程安全，与 steal 线程安全
  bool pop(T* val) {
    const size_t b = _bottom.load(butil::memory_order_relaxed);
    size_t t = _top.load(butil::memory_order_relaxed);
    if (t >= b) {
      // fast check since we call pop() in each sched.
      // Stale _top which is smaller should not enter this branch.
      return false;
    }
    const size_t newb = b - 1;
    _bottom.store(newb, butil::memory_order_relaxed);
    butil::atomic_thread_fence(butil::memory_order_seq_cst);
    t = _top.load(butil::memory_order_relaxed);
    if (t > newb) {
      _bottom.store(b, butil::memory_order_relaxed);
      return false;
    }
    *val = _buffer[newb & (_capacity - 1)];
    if (t != newb) {
      return true;
    }
    // Single last element, compete with steal()
    // 对于最后一个元素，使用 CAS 保证和 steal 并发时的线程安全
    const bool popped = _top.compare_exchange_strong(
        t, t + 1, butil::memory_order_seq_cst, butil::memory_order_relaxed);
    _bottom.store(b, butil::memory_order_relaxed);
    return popped;
  }

  // 从顶部窃取，线程安全
  bool steal(T* val) {
    size_t t = _top.load(butil::memory_order_acquire);
    size_t b = _bottom.load(butil::memory_order_acquire);
    if (t >= b) {
      // Permit false negative for performance considerations.
      return false;
    }
    do {
      butil::atomic_thread_fence(butil::memory_order_seq_cst);
      b = _bottom.load(butil::memory_order_acquire);
      if (t >= b) {
        return false;
      }
      *val = _buffer[t & (_capacity - 1)];
      // CAS 保证线程安全
    } while (!_top.compare_exchange_strong(
        t, t + 1, butil::memory_order_seq_cst, butil::memory_order_relaxed));
    return true;
  }

 private:
  // Copying a concurrent structure makes no sense.
  DISALLOW_COPY_AND_ASSIGN(WorkStealingQueue);

  butil::atomic<size_t> _bottom;
  size_t _capacity;
  T* _buffer;
  butil::atomic<size_t> BAIDU_CACHELINE_ALIGNMENT _top;  // 分开到两个 CacheLine
};
```

`push` 和 `pop` 仅在底部操作，非线程安全。`steal` 仅在顶部窃取，通过 CAS 保证线程安全。

接着来看 bthread 启动的流程：

```c++
// test/bthread_unittest.cpp
TEST_F(BthreadTest, sanity) {
  LOG(INFO) << "main thread " << pthread_self();
  bthread_t th1;
  ASSERT_EQ(0, bthread_start_urgent(&th1, NULL, misc, (void*)1));
  LOG(INFO) << "back to main thread " << th1 << " " << pthread_self();
  ASSERT_EQ(0, bthread_join(th1, NULL));
}


// bthread.cpp
int bthread_start_urgent(bthread_t* __restrict tid,
                         const bthread_attr_t* __restrict attr,
                         void * (*fn)(void*),
                         void* __restrict arg) {
  bthread::TaskGroup* g = bthread::tls_task_group;
  if (g) {
    // start from worker
    return bthread::TaskGroup::start_foreground(&g, tid, attr, fn, arg);
  }
  // 首次执行，需要初始化
  return bthread::start_from_non_worker(tid, attr, fn, arg);
}

BUTIL_FORCE_INLINE int
  start_from_non_worker(bthread_t* __restrict tid,
                        const bthread_attr_t* __restrict attr,
                        void * (*fn)(void*),
                        void* __restrict arg) {
  // 获取 TaskControl 全局单例
  TaskControl* c = get_or_new_task_control();
  if (NULL == c) {
    return ENOMEM;
  }
  if (attr != NULL && (attr->flags & BTHREAD_NOSIGNAL)) {
    // Remember the TaskGroup to insert NOSIGNAL tasks for 2 reasons:
    // 1. NOSIGNAL is often for creating many bthreads in batch,
    //    inserting into the same TaskGroup maximizes the batch.
    // 2. bthread_flush() needs to know which TaskGroup to flush.
    TaskGroup* g = tls_task_group_nosignal;
    if (NULL == g) {
      g = c->choose_one_group();
      tls_task_group_nosignal = g;
    }
    return g->start_background<true>(tid, attr, fn, arg);
  }
  // 加入队列
  return c->choose_one_group()->start_background<true>(
    tid, attr, fn, arg);
}

inline TaskControl* get_or_new_task_control() {
  butil::atomic<TaskControl*>* p = (butil::atomic<TaskControl*>*)&g_task_control;
  TaskControl* c = p->load(butil::memory_order_consume);
  if (c != NULL) {
    return c;
  }
  BAIDU_SCOPED_LOCK(g_task_control_mutex);  // 全局锁
  c = p->load(butil::memory_order_consume);
  if (c != NULL) {
    return c;
  }
  c = new (std::nothrow) TaskControl;
  if (NULL == c) {
    return NULL;
  }
  int concurrency = FLAGS_bthread_min_concurrency > 0 ?
    FLAGS_bthread_min_concurrency :
  FLAGS_bthread_concurrency;
  // 初始化，concurrency 为工作线程数
  if (c->init(concurrency) != 0) {
    LOG(ERROR) << "Fail to init g_task_control";
    delete c;
    return NULL;
  }
  p->store(c, butil::memory_order_release);
  return c;
}


// task_control.cpp
int TaskControl::init(int concurrency) {
  if (_concurrency != 0) {
    LOG(ERROR) << "Already initialized";
    return -1;
  }
  if (concurrency <= 0) {
    LOG(ERROR) << "Invalid concurrency=" << concurrency;
    return -1;
  }
  _concurrency = concurrency;

  // Make sure TimerThread is ready.
  if (get_or_create_global_timer_thread() == NULL) {
    LOG(ERROR) << "Fail to get global_timer_thread";
    return -1;
  }

  _workers.resize(_concurrency);   
  for (int i = 0; i < _concurrency; ++i) {
    // 启动工作线程
    const int rc = pthread_create(&_workers[i], NULL, worker_thread, this);
    if (rc) {
      LOG(ERROR) << "Fail to create _workers[" << i << "], " << berror(rc);
      return -1;
    }
  }
  _worker_usage_second.expose("bthread_worker_usage");
  _switch_per_second.expose("bthread_switch_second");
  _signal_per_second.expose("bthread_signal_second");
  _status.expose("bthread_group_status");

  // Wait for at least one group is added so that choose_one_group()
  // never returns NULL.
  // TODO: Handle the case that worker quits before add_group
  while (_ngroup == 0) {
    usleep(100);  // TODO: Elaborate
  }
  return 0;
}
```

bthread 后台会开启多个 `worker_thread` 线程执行 bthread 任务：

```c++
// task_control.cpp
void* TaskControl::worker_thread(void* arg) {
  run_worker_startfn();

  TaskControl* c = static_cast<TaskControl*>(arg);
  TaskGroup* g = c->create_group();  // 每个线程有一个对应的 TaskGroup
  TaskStatistics stat;
  if (NULL == g) {
    LOG(ERROR) << "Fail to create TaskGroup in pthread=" << pthread_self();
    return NULL;
  }
  BT_VLOG << "Created worker=" << pthread_self()
    << " bthread=" << g->main_tid();

  tls_task_group = g;  // 使用 TLS 存储线程对应的 TaskGroup
  c->_nworkers << 1;
  g->run_main_task();  // 任务主循环

  stat = g->main_stat();
  BT_VLOG << "Destroying worker=" << pthread_self() << " bthread="
    << g->main_tid() << " idle=" << stat.cputime_ns / 1000000.0
    << "ms uptime=" << g->current_uptime_ns() / 1000000.0 << "ms";
  tls_task_group = NULL;
  g->destroy_self();
  c->_nworkers << -1;
  return NULL;
}


// task_group.cpp
void TaskGroup::run_main_task() {
  bvar::PassiveStatus<double> cumulated_cputime(
    get_cumulated_cputime_from_this, this);
  std::unique_ptr<bvar::PerSecond<bvar::PassiveStatus<double> > > usage_bvar;

  TaskGroup* dummy = this;
  bthread_t tid;
  while (wait_task(&tid)) {  // 获取任务
    TaskGroup::sched_to(&dummy, tid);  // 调度执行
    DCHECK_EQ(this, dummy);
    DCHECK_EQ(_cur_meta->stack, _main_stack);
    if (_cur_meta->tid != _main_tid) {
      TaskGroup::task_runner(1/*skip remained*/);
    }
  }
}

bool TaskGroup::wait_task(bthread_t* tid) {
  do {
    if (_last_pl_state.stopped()) {
      return false;
    }
    _pl->wait(_last_pl_state);
    if (steal_task(tid)) {  // 窃取任务
      return true;
    }
  } while (true);
}

bool steal_task(bthread_t* tid) {
  // 本地队列中有任务，优先本地
  if (_remote_rq.pop(tid)) {
    return true;
  }
  // 否则通过 TaskControl 窃取全局的任务
  return _control->steal_task(tid, &_steal_seed, _steal_offset);
}


// task_control.cpp
bool TaskControl::steal_task(bthread_t* tid, size_t* seed, size_t offset) {
  // 1: Acquiring fence is paired with releasing fence in _add_group to
  // avoid accessing uninitialized slot of _groups.
  const size_t ngroup = _ngroup.load(butil::memory_order_acquire/*1*/);
  if (0 == ngroup) {
    return false;
  }

  // NOTE: Don't return inside `for' iteration since we need to update |seed|
  bool stolen = false;
  size_t s = *seed;
  for (size_t i = 0; i < ngroup; ++i, s += offset) {
    TaskGroup* g = _groups[s % ngroup];
    // g is possibly NULL because of concurrent _destroy_group
    if (g) {
      if (g->_rq.steal(tid)) {  // 无锁窃取
        stolen = true;
        break;
      }
      if (g->_remote_rq.pop(tid)) {  // 有锁窃取
        stolen = true;
        break;
      }
    }
  }
  *seed = s;
  return stolen;
}


// task_group_inl.h
inline void TaskGroup::sched_to(TaskGroup** pg, bthread_t next_tid) {
  TaskMeta* next_meta = address_meta(next_tid);
  if (next_meta->stack == NULL) {
    ContextualStack* stk = get_stack(next_meta->stack_type(), task_runner);
    if (stk) {
      next_meta->set_stack(stk);
    } else {
      // stack_type is BTHREAD_STACKTYPE_PTHREAD or out of memory,
      // In latter case, attr is forced to be BTHREAD_STACKTYPE_PTHREAD.
      // This basically means that if we can't allocate stack, run
      // the task in pthread directly.
      next_meta->attr.stack_type = BTHREAD_STACKTYPE_PTHREAD;
      next_meta->set_stack((*pg)->_main_stack);
    }
  }
  // Update now_ns only when wait_task did yield.
  sched_to(pg, next_meta);  // 执行
}


// task_group.cpp
void TaskGroup::sched_to(TaskGroup** pg, TaskMeta* next_meta) {
  TaskGroup* g = *pg;
  // Save errno so that errno is bthread-specific.
  const int saved_errno = errno;
  void* saved_unique_user_ptr = tls_unique_user_ptr;

  TaskMeta* const cur_meta = g->_cur_meta;
  const int64_t now = butil::cpuwide_time_ns();
  const int64_t elp_ns = now - g->_last_run_ns;
  g->_last_run_ns = now;
  cur_meta->stat.cputime_ns += elp_ns;
  if (cur_meta->tid != g->main_tid()) {
    g->_cumulated_cputime_ns += elp_ns;
  }
  ++cur_meta->stat.nswitch;
  ++ g->_nswitch;
  // Switch to the task
  if (__builtin_expect(next_meta != cur_meta, 1)) {
    g->_cur_meta = next_meta;
    // Switch tls_bls
    cur_meta->local_storage = tls_bls;
    tls_bls = next_meta->local_storage;

    // Logging must be done after switching the local storage, since the logging lib
    // use bthread local storage internally, or will cause memory leak.
    if ((cur_meta->attr.flags & BTHREAD_LOG_CONTEXT_SWITCH) ||
        (next_meta->attr.flags & BTHREAD_LOG_CONTEXT_SWITCH)) {
      LOG(INFO) << "Switch bthread: " << cur_meta->tid << " -> "
        << next_meta->tid;
    }

    if (cur_meta->stack != NULL) {
      if (next_meta->stack != cur_meta->stack) {
        jump_stack(cur_meta->stack, next_meta->stack);  // 协程切换
        // probably went to another group, need to assign g again.
        g = tls_task_group;
      }
    }
    // else because of ending_sched(including pthread_task->pthread_task)
  } else {
    LOG(FATAL) << "bthread=" << g->current_tid() << " sched_to itself!";
  }

  while (g->_last_context_remained) {
    RemainedFn fn = g->_last_context_remained;
    g->_last_context_remained = NULL;
    fn(g->_last_context_remained_arg);
    g = tls_task_group;
  }

  // Restore errno
  errno = saved_errno;
  tls_unique_user_ptr = saved_unique_user_ptr;

  *pg = g;
}

// stack_inl.h
inline void jump_stack(ContextualStack* from, ContextualStack* to) {
  bthread_jump_fcontext(&from->context, to->context, 0/*not skip remained*/);
}
```

从外部线程通过 TaskControl 新增 bthread 的流程：

```c++
// task_group.cpp
template <bool REMOTE>
int TaskGroup::start_background(bthread_t* __restrict th,
                                const bthread_attr_t* __restrict attr,
                                void * (*fn)(void*),
                                void* __restrict arg) {
    if (__builtin_expect(!fn, 0)) {
        return EINVAL;
    }
    const int64_t start_ns = butil::cpuwide_time_ns();
    const bthread_attr_t using_attr = (attr ? *attr : BTHREAD_ATTR_NORMAL);
    butil::ResourceId<TaskMeta> slot;
    TaskMeta* m = butil::get_resource(&slot);
    if (__builtin_expect(!m, 0)) {
        return ENOMEM;
    }
    CHECK(m->current_waiter.load(butil::memory_order_relaxed) == NULL);
    m->stop = false;
    m->interrupted = false;
    m->about_to_quit = false;
    m->fn = fn;
    m->arg = arg;
    CHECK(m->stack == NULL);
    m->attr = using_attr;
    m->local_storage = LOCAL_STORAGE_INIT;
    m->cpuwide_start_ns = start_ns;
    m->stat = EMPTY_STAT;
    m->tid = make_tid(*m->version_butex, slot);
    *th = m->tid;
    if (using_attr.flags & BTHREAD_LOG_START_AND_FINISH) {
        LOG(INFO) << "Started bthread " << m->tid;
    }
    _control->_nbthreads << 1;
    if (REMOTE) {
        // 外部线程
        ready_to_run_remote(m->tid, (using_attr.flags & BTHREAD_NOSIGNAL));
    } else {
        ready_to_run(m->tid, (using_attr.flags & BTHREAD_NOSIGNAL));
    }
    return 0;
}

void TaskGroup::ready_to_run_remote(bthread_t tid, bool nosignal) {
    // 加锁后加入队列
    _remote_rq._mutex.lock();
    while (!_remote_rq.push_locked(tid)) {
        flush_nosignal_tasks_remote_locked(_remote_rq._mutex);
        LOG_EVERY_SECOND(ERROR) << "_remote_rq is full, capacity="
                                << _remote_rq.capacity();
        ::usleep(1000);
        _remote_rq._mutex.lock();
    }
    if (nosignal) {
        ++_remote_num_nosignal;
        _remote_rq._mutex.unlock();
    } else {
        const int additional_signal = _remote_num_nosignal;
        _remote_num_nosignal = 0;
        _remote_nsignaled += 1 + additional_signal;
        _remote_rq._mutex.unlock();
        _control->signal_task(1 + additional_signal);  // 唤醒工作线程执行任务
    }
}
```

### PS：一些题外话

没错，[Tokio 源码分析](/#/Tokio)被“鸽”置了。去年下半年组里项目非常忙，导致周末也不想学习。好在项目赶在年前上线了，年初的答辩也挺顺利，今年就有更多时间自我提升了。开 bRPC 的新坑是因为该项目里有不少先进经验可以应用到自己的工作上，Tokio 会排在 bRPC 之后补上。

