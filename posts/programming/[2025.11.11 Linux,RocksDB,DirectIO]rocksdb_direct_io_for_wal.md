# RocksDB Sync Write on HDD 性能优化

### 1. 背景

业务需求，需要在 HDD 上使用 RocksDB 并且每一笔写入都需要确保落盘，即写入返回成功后立即断电，重新加载也能完整恢复数据。每次写入实际上只有 100B 左右，需要尽可能地降低延迟。发现在 HDD 上 RocksDB 的 sync write 性能非常差，平均在 30ms 以上。而业务上又很难将多笔写入合并为大的 write batch 一次落盘，故有了本文中阐述的方案。

### 2. 分析

RocksDB 的 sync write 性能差，核心原因是使用 buffer IO 模式写完 WAL 文件后，`fdatasync` 的性能太差了。如果替换成 direct IO，应该可以规避 `fdatasync`。跟 AI 简单聊了两句，发现 RocksDB 上 SST 文件已经支持了 direct IO 读写了，讲道理让 WAL 支持 direct IO 应该不会太困难。

此时我又在忙别的活，就让 Copilot 帮我写一版，PR 在[这里](https://github.com/SF-Zhou/rocksdb/pull/1)。Copilot 改的非常简单，第一眼我看着以为是瞎改。跟它掰扯了几下，又看了下代码，发现它做的是对的。一来 RocksDB 本身支持使用 direct IO 写文件，会在内存里维护最后一部分非对齐的内容，每次追加时会覆盖写最后的 512B，padding 部分会填充 0；二来 WAL 是支持跳过全 0 的记录的，意外断电恢复也就不是事了。

简单过了下单元测试，就开始将这个修改集成当我们的系统中，意外地发现性能非常好。启用 direct IO + sync，单次写入平均延迟降低到 4ms，直接变可用了！所以 `fdatasync` 性能差，推测本质上是小写入时 page cache 的性能太差了。

我也跑了一下 RocksDB 自带的 db_bench，能看到 direct IO + sync 远超 buffer IO + sync，所以我给官方也提了一个 PR：https://github.com/facebook/rocksdb/pull/14116

```bash
# disable use_direct_io_for_wal.
./db_bench --benchmarks=fillseq --db=/storage/data1/rocksdb --num=10000 --value_size=128 --sync=true --use_direct_io_for_wal=false
#> fillseq      :   25555.892 micros/op 39 ops/sec 255.559 seconds 10000 operations;    0.0 MB/s

# enable use_direct_io_for_wal.
./db_bench --benchmarks=fillseq --db=/storage/data1/rocksdb --num=10000 --value_size=128 --sync=true --use_direct_io_for_wal=true
#> fillseq      :     519.530 micros/op 1924 ops/sec 5.195 seconds 10000 operations;    0.3 MB/s
```

### 3. 其他

既然已经使用了 direct IO，那么 sync 还是有必要的吗？实际上还是有必要的。文件大小元数据以及文件内部 extent 状态都需要 fdatasync 才能确保落盘，如果不 sync 一下直接断电，还是有丢数据的风险。我也测试了只 direct IO 不 sync 的性能，与 direct IO + sync 性能基本一致，所以就不折腾[只 direct IO 的方案](https://github.com/SF-Zhou/rocksdb/pull/2)了。

> 预期 WAL 使用 direct io 写入后，配合企业级硬盘的 PLDP 能力，就不再需要 fdatasync 强制保证落盘了。但是每次  write 到尾部还是需要修改文件长度元数据，一个可行的优化策略是在数据 write 前，事先在文件尾部写入一块足够大的区域填充全 0，并且使用 fdatasync 将文件长度落盘，后续用户写入的 write batch 都在这个全 0  的区域内，并且也不需要再修改文件长度了。帮我增加一个配置，表示预分配的块大小，使用后台线程进行填充 0 和 fdatasync  操作。当预分配的块大小使用空间超过一半时，则继续触发下一个块的预分配。注意和正常用户写的并发安全，以及文件长度和用户数据长度的安全修改。

另外，AI 真的越来越好用了，真真切切地提高了生产力。